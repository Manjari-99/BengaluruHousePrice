# -*- coding: utf-8 -*-
"""House_Price_Predictor.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15K5miI5qkEStY7AFmID9CK_ZUp_YHS5B

#**Bengaluru Real Estate Price prediction model**
**We, will predict the hour price based on certain constraints**
"""

# Commented out IPython magic to ensure Python compatibility.
#lets first import the modules and libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

#lets import and see the dataset
df = pd.read_csv('Bengaluru_House_Data.csv')

df.sample(10)

"""**We will now clean the data and remove unnecessary columns**"""

df.info()

#lets find null values
df.isnull().sum()

df['society'].value_counts()
#a lot of null values

#plotting with respect to price
plt.rcParams["figure.figsize"] = (25,18)
sns.scatterplot(df['society'],df['price'])
plt.title('Society VS Price')
plt.ylabel('Price')
plt.xlabel('Society')
plt.show()

#no variation in price with society, also a lot of null values, so we drop society column
df.drop(columns=['society'],inplace=True)

#now lets find the rest of the null values

df.isnull().sum()

df.corr()
#low correlation so we remove

#we next handle balcony column
plt.rcParams["figure.figsize"] = (12,10)
sns.boxplot(df['balcony'],df['price'],hue=df['balcony'])
plt.title('Balcony VS Price')
plt.ylabel('Price')
plt.xlabel('Balcony')
plt.show()

#not a lot of variation in price, many outliers as well as null values, hence we drop the column
df.drop(columns=['balcony'],inplace=True)

df.isnull().sum()

#we next handle bath
df.corr()

#bathroom has moderate correlation, hence we do not remove this columns
df.shape

#we drop the null columns
df = df.dropna()
df.isnull().sum()

"""Now there are no null values"""

#we now drop duplicate values
df = df.drop_duplicates()
df.shape

"""***The data is free from null values and duplicates.
  Now lets remove columns that do not affect the house price***



"""

df.head()

"""1. **Lets analyse Area Type**"""

df['area_type'].value_counts().shape
#4 differect types, hence scatter plot

#lets visualize the data, with respect to area-type
sns.scatterplot(df['area_type'],df['price'],hue=df['area_type'])

#we see the price does not vary with area type, same area type has different prices, different area types may have the same price as well.

from sklearn.preprocessing import LabelEncoder
lb = LabelEncoder()
df['area_type'] = lb.fit_transform(df['area_type'])
df.head()

df.corr()['price']
#since area type has very low correlation, we drop it

df.drop(columns=['area_type'],inplace=True)

"""2. Availability"""

df['availability'].value_counts().shape

#encode it
df['availability'] = lb.fit_transform(df['availability'])

#lets find the correlation
df.corr()['price']

#since availability has very low correlation, we drop it

df.drop(columns=['availability'],inplace=True)

df.head()

"""3. **Location**"""

sns.scatterplot(df['location'],df['price'])
plt.title('Location VS Price')
plt.ylabel('Price')
plt.xlabel('Location')
plt.show()

#remove outlying locations,to avoid overfitting
locations = df.groupby('location')['location'].value_counts().sort_values()
locations= locations[locations<=10]

df['location']=df['location'].apply(lambda x : 'Others' if x in locations else x)
df['location'].value_counts()

#we now encode the location so that it can be used in the model
lb = LabelEncoder()
df['location'] = lb.fit_transform(df['location'])
df.head()

"""4. **Total Square Feet Area**"""

df.sample(10)

#we also have ranges,and also alphabets , we need to change that to a single valued number
df['total_sqft'] = df['total_sqft'].astype(str)

#function to change it to only numeric
def onlynum(x):
    temp=""
    if x[-1].isalpha():
        for i in range(len(x)):
            if x[i].isnumeric():
                temp +=x[i]
        return temp
    else:
        return x

df['total_sqft'] = df['total_sqft'].apply(lambda x: onlynum(x))

#function to remove ranges
def norange(x):
    temp=x.split('-')
    if len(temp)==2:
        return (float(temp[0])+float(temp[1]))/2
    else:
        return float(x)

df['total_sqft'] = df['total_sqft'].apply(lambda x: norange(x))

df['total_sqft'].unique()

df['total_sqft'] = df['total_sqft'].astype(float)

"""5. **Bathrooms**"""

df['bath'].value_counts()

sns.scatterplot(df['bath'],df['price'])

#we remove outliers
df['bath'].value_counts()
bathroom = df.groupby('bath')['bath'].value_counts().sort_values()
bathroom = bathroom[bathroom<=3]

df['bath'] = df['bath'].apply(lambda x: 0 if x in bathroom else x)
df['bath'].value_counts()

df = df[df['bath']>0]

df['bath'].value_counts()

df.corr()['price']['bath']

df['bath'] = df['bath'].astype(int)

"""**6.BHK**"""

df['size'].value_counts()

#we next extract the BHK value from size column
df['size'] = df['size'].astype(str)
df['bhk'] = df['size'].apply(lambda x: x.split()[0])
df.head()

df.drop(columns=['size'],inplace=True)

df['bhk'] = df['bhk'].astype(int)

df.corr()['price']['bhk']

df['bhk']=df['bhk'].astype(float)

df.info()

"""**We now remove the overall outliers**"""

#we remove outliiers
#remove extremely small houses that no one would buy
df =df[df['total_sqft']/df['bhk']>=350].iloc[:,:]

df['price_per_sqft'] = (df['price']*100000)/df['bhk']

def removeoutliers(x):
    df1 = pd.DataFrame()
    for key,subdf in x.groupby('location'):
        m = np.mean(subdf.price_per_sqft)
        st = np.std(subdf.price_per_sqft)
        reducedf = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft>(m-st))]
        df1 = pd.concat([df1,reducedf],ignore_index=True)
    return df1

df = removeoutliers(df)

df.drop(columns=['price_per_sqft'],inplace=True)

#remove unrealistic houses where there are more bathrooms than rooms
 df = df[df['bath']<=df['bhk']].iloc[:,:]
 df.shape

"""**We now Train the Data**"""

df.head()

X = df.drop(columns=['price']).iloc[:,:]

y=df['price'].values

y.shape

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)

from sklearn.ensemble import RandomForestRegressor

regressor = RandomForestRegressor(criterion='mse',random_state=0)
regressor.fit(X_train, y_train)
y_pred = regressor.predict(X_test)

"""**We now test the data**"""

from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_test,y_pred)
rmse = np.sqrt(mse)
rmse

from sklearn.metrics import r2_score
r2_score(y_test,y_pred)

"""**We now import pickle to import the models as a pickle file**"""

import pickle 
pickle.dump(lb, open('loc_encoder.pkl','wb'))

pickle.dump(regressor,open('rfr.pkl','wb'))

